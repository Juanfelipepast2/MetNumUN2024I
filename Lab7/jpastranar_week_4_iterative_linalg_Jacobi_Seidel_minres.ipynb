{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juanfelipepast2/MetNumUN2024I/blob/main/Lab7/jpastranar_Lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxMJ2_fyncc9"
      },
      "source": [
        "# Simple iteration for systems of linear equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GravMmFBncdB"
      },
      "source": [
        "First, generate a random diagonally dominant matrix, for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "EDJmeMM_ncdC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rndm = np.random.RandomState(1234)\n",
        "\n",
        "n = 10\n",
        "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
        "b = rndm.uniform(size=n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1kAe0KkncdD"
      },
      "source": [
        "# I.  Jacobi iteration\n",
        "\n",
        "Given\n",
        "\n",
        "$$\n",
        "A x = b\n",
        "$$\n",
        "\n",
        "separate the diagonal part $D$,\n",
        "\n",
        "$$ A = D + (A - D) $$\n",
        "\n",
        "and write\n",
        "\n",
        "$$\n",
        "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
        "$$\n",
        "\n",
        "Then iterate\n",
        "\n",
        "$$\n",
        "x_{n + 1} = B x_{n} + c\\;,\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYbDsaDhncdE"
      },
      "source": [
        "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BwXPGvmvncdE"
      },
      "outputs": [],
      "source": [
        "diag_1d = np.diag(A)\n",
        "\n",
        "B = -A.copy()\n",
        "np.fill_diagonal(B, 0)\n",
        "\n",
        "D = np.diag(diag_1d)\n",
        "invD = np.diag(1./diag_1d)\n",
        "BB = invD @ B\n",
        "c = invD @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AqATbH6rncdE"
      },
      "outputs": [],
      "source": [
        "# sanity checks\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "assert_allclose(-B + D, A)\n",
        "\n",
        "\n",
        "# xx is a \"ground truth\" solution, compute it using a direct method\n",
        "xx = np.linalg.solve(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@xx, b)\n",
        "np.testing.assert_allclose(D@xx, B@xx + b)\n",
        "np.testing.assert_allclose(xx, BB@xx + c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUj6eczLncdF"
      },
      "source": [
        "Check that $\\| B\\| \\leqslant 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "94J2RpudncdF",
        "outputId": "36cd59f1-bc9f-4ee9-96f1-842050983e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36436161983015336"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.linalg.norm(BB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EAOMPafncdG"
      },
      "source": [
        "### Do the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "iWGh3rJbncdG"
      },
      "outputs": [],
      "source": [
        "n_iter = 50\n",
        "\n",
        "x0 = np.ones(n)\n",
        "x = x0\n",
        "for _ in range(n_iter):\n",
        "    x = BB @ x + c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k062IS1MncdG",
        "outputId": "7fb158e8-42ec-4f0e-d0b3-e80ecbcf2f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
              "        1.11022302e-16,  0.00000000e+00, -2.42861287e-17,  0.00000000e+00,\n",
              "       -2.77555756e-17,  1.11022302e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check the result:\n",
        "\n",
        "A @ x - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TjMuFkPncdH"
      },
      "source": [
        "### Task I.1\n",
        "\n",
        "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
        "\n",
        "\n",
        "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction.\n",
        "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
        "\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "a8gKq1vBncdH",
        "outputId": "25ecdcbd-3f9f-4c83-d625-9591495e88a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution using Jacobi iteration: [0.05360242 0.07813839 0.09829767]\n",
            "Norm of matrix B: 0.75\n"
          ]
        }
      ],
      "source": [
        "# ... ENTER YOUR CODE HERE ...\n",
        "import numpy as np\n",
        "\n",
        "def jacobi_iteration(A, b, num_iterations):\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "\n",
        "    D = np.diag(np.diag(A))\n",
        "    R = A - D\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        x_new = (b - np.dot(R, x)) / np.diag(D)\n",
        "        x = x_new\n",
        "\n",
        "    return x\n",
        "\n",
        "def check_convergence(A):\n",
        "    D = np.diag(np.diag(A))\n",
        "    R = A - D\n",
        "    B = np.linalg.inv(D).dot(R)\n",
        "    norm_B = np.linalg.norm(B, ord=np.inf)\n",
        "\n",
        "    return norm_B\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[10, 2, 3],\n",
        "              [4, 15, 6],\n",
        "              [7, 8, 20]])\n",
        "b = np.array([1, 2, 3])\n",
        "num_iterations = 10\n",
        "\n",
        "solution = jacobi_iteration(A, b, num_iterations)\n",
        "norm_B = check_convergence(A)\n",
        "\n",
        "print(\"Solution using Jacobi iteration:\", solution)\n",
        "print(\"Norm of matrix B:\", norm_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCOq_mz7ncdH"
      },
      "source": [
        "# II. Seidel's iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te9MsGBencdH"
      },
      "source": [
        "##### Task II.1\n",
        "\n",
        "Implement the Seidel's iteration.\n",
        "\n",
        "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "JLE32zMxncdH",
        "outputId": "e0c61cf8-52a2-4374-f0b4-2b17a024ec96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution using Gauss-Seidel iteration: [ 0.2000545   5.17716694 -5.86584675]\n",
            "Norm of matrix T: 22.965739532413963\n"
          ]
        }
      ],
      "source": [
        "# ... ENTER YOUR CODE HERE ...\n",
        "import numpy as np\n",
        "\n",
        "def gauss_seidel_iteration(A, b, num_iterations):\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        x_new = np.copy(x)\n",
        "        for i in range(n):\n",
        "            x_new[i] = (b[i] - np.dot(A[i, :i], x_new[:i]) - np.dot(A[i, i + 1:], x[i + 1:])) / A[i, i]\n",
        "        x = x_new\n",
        "\n",
        "    return x\n",
        "\n",
        "def study_convergence(A):\n",
        "    L = np.tril(A, k=-1)\n",
        "    U = np.triu(A, k=1)\n",
        "    D = np.diag(np.diag(A))\n",
        "\n",
        "    T = -np.linalg.inv(L + D).dot(U)\n",
        "    norm_T = np.linalg.norm(T, ord=np.inf)\n",
        "\n",
        "    return norm_T\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "random_matrix = np.random.rand(3, 3)\n",
        "random_vector = np.random.rand(3)\n",
        "num_iterations = 10\n",
        "\n",
        "solution_seidel = gauss_seidel_iteration(random_matrix, random_vector, num_iterations)\n",
        "norm_T = study_convergence(random_matrix)\n",
        "\n",
        "print(\"Solution using Gauss-Seidel iteration:\", solution_seidel)\n",
        "print(\"Norm of matrix T:\", norm_T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdl3FS71ncdH"
      },
      "source": [
        "# III. Minimum residual scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nObK6vkgncdH"
      },
      "source": [
        "### Task III.1\n",
        "\n",
        "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
        "\n",
        "(50% of the grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "DD4ZGftYncdI",
        "outputId": "cc7e4604-7be7-4c65-cc6d-418caad4ae69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1 - Residual Norm: 0.6402891257761572, Deviation from Truth: 8.379739397787493, Tau: 0.7711771263434366\n",
            "Iteration: 2 - Residual Norm: 0.6066785342518726, Deviation from Truth: 7.304991999196145, Tau: -1.7000294817348063\n",
            "Iteration: 3 - Residual Norm: 0.5944799340897743, Deviation from Truth: 7.473538055144704, Tau: 0.31411795990756675\n",
            "Iteration: 4 - Residual Norm: 0.592822897061918, Deviation from Truth: 7.358003698906767, Tau: -0.20231136582600817\n",
            "Iteration: 5 - Residual Norm: 0.5924147256123201, Deviation from Truth: 7.401822719639131, Tau: 0.0788902878079138\n"
          ]
        }
      ],
      "source": [
        "# ... ENTER YOUR CODE HERE ...\n",
        "import numpy as np\n",
        "\n",
        "def minimum_residual_scheme(A, b, num_iterations):\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "    x_truth = np.linalg.solve(A, b)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        r = b - A.dot(x)\n",
        "        tau = np.dot(r, A.dot(r)) / np.dot(A.dot(r), A.dot(r))\n",
        "        x = x + tau * r\n",
        "\n",
        "        residual_norm = np.linalg.norm(b - A.dot(x))\n",
        "        deviation_truth = np.linalg.norm(x - x_truth)\n",
        "\n",
        "        print(f\"Iteration: {_+1} - Residual Norm: {residual_norm}, Deviation from Truth: {deviation_truth}, Tau: {tau}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "random_matrix = np.random.rand(3, 3)\n",
        "random_vector = np.random.rand(3)\n",
        "num_iterations = 5\n",
        "\n",
        "solution_minimum_residual = minimum_residual_scheme(random_matrix, random_vector, num_iterations)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
